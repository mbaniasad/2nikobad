\relax 
\citation{einshams}
\citation{naiveBayes}
\citation{explainW2V}
\citation{enrichWordvecs-with-subwords}
\citation{naiveBayes}
\@writefile{toc}{\contentsline {title}{A sequence learning approach to sentiment analysis on call-center conversation data}{1}}
\@writefile{toc}{\authcount {2}}
\@writefile{toc}{\contentsline {author}{Mohammad\nobreakspace  {}Baniasad\unskip {} \and Mohammad reza yousefi\unskip {}}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {paragraph}{T}{1}}
\citation{imdbdataset}
\citation{imdbdataset}
\citation{crosslinguistic-dataset}
\citation{crosslinguistic-dataset}
\@writefile{toc}{\contentsline {section}{\numberline {2}DATASETS}{2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Datasets and their features.}}{2}}
\newlabel{tbl:datasets}{{1}{2}}
\citation{naiveBayes}
\citation{scikit-learn}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiments}{3}}
\@writefile{toc}{\contentsline {paragraph}{A}{3}}
\newlabel{eq:bayes-equation}{{1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces accuracy of Bayes classifier.}}{3}}
\newlabel{acc-test-bayes}{{1}{3}}
\citation{Graves2012}
\citation{UnreasonableRNN}
\citation{tflearn2016}
\citation{tensorflow2015-whitepaper}
\@writefile{toc}{\contentsline {paragraph}{O}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces LSTM accuracy on IMDB reviews dataset using different optimizers}}{4}}
\newlabel{fig:choosingOpitmizer}{{2}{4}}
\citation{explainW2V}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces LSTM accuracy on IMDB reviews dataset using different optimizers}}{5}}
\newlabel{fig:selectingEpochs}{{3}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces effect of dropout in accuracy on different dataset}}{5}}
\newlabel{fig:dropoutOnAccuracy}{{4}{5}}
\citation{efficentw2v}
\citation{gensim}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Captured semantic information in the form of distance using word2vec algorithm}}{6}}
\newlabel{fig:word2vec-gender-relation}{{5}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces doc2vec accuracy over different datasets}}{6}}
\newlabel{tbl:doc2vec-accuracy-datasets}{{2}{6}}
\citation{enrichWordvecs-with-subwords}
\citation{Bag-of-Tricks}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Accuracy of LSTM classifier on top doc2vec input}}{7}}
\newlabel{fig:LSTMdoc2vec}{{6}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces fast-text algorithm accuracy over different datasets}}{7}}
\newlabel{tbl:fasttext-accuracy-datasets }{{3}{7}}
\bibstyle{unsrt}
\bibdata{bibexample}
\bibcite{einshams}{1}
\bibcite{naiveBayes}{2}
\bibcite{explainW2V}{3}
\bibcite{enrichWordvecs-with-subwords}{4}
\bibcite{imdbdataset}{5}
\bibcite{crosslinguistic-dataset}{6}
\bibcite{scikit-learn}{7}
\bibcite{Graves2012}{8}
\bibcite{UnreasonableRNN}{9}
\bibcite{tflearn2016}{10}
\bibcite{tensorflow2015-whitepaper}{11}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Future works}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Acknowledgements}{8}}
\bibcite{efficentw2v}{12}
\bibcite{gensim}{13}
\bibcite{Bag-of-Tricks}{14}
